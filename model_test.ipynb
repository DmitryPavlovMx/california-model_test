{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870a1090-f4ae-45a0-aa93-0960f5c6478d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453c78e8-6822-4123-bf9d-ed1ae9dd7bea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# specify substep parameters for interactive run\n",
    "# this cell will be replaced during job run with the parameters from json within params subfolder\n",
    "substep_params={\n",
    "    \"mae_threshold\":1.5 ,\n",
    "    \"mape_threshold\":0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50592002-8b5f-47bd-82a7-3489fd1f5b1c",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Pipeline params:**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': 'something',\n",
      " 'env_name': 'user',\n",
      " 'pipeline_name': 'pipeline',\n",
      " 'zone_name': 'zone'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Step params:**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Y': 'something_else'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load pipeline and step parameters - do not edit\n",
    "from sinara.substep import get_pipeline_params, get_step_params\n",
    "pipeline_params = get_pipeline_params(pprint=True)\n",
    "step_params = get_step_params(pprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3818420-6085-43ea-b97e-578742794e1e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "interface"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**STEP NAME:**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'model_test'\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**INPUTS:**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user.pipeline.zone.model_train.california_bento': '/data/home/jovyan/pipeline/zone/model_train/run-25-01-15-070811/california_bento'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3 define substep interface\n",
    "from sinara.substep import NotebookSubstep, ENV_NAME, PIPELINE_NAME, ZONE_NAME, STEP_NAME, RUN_ID, ENTITY_NAME, ENTITY_PATH, SUBSTEP_NAME\n",
    "\n",
    "substep = NotebookSubstep(pipeline_params, step_params, substep_params)\n",
    "\n",
    "substep.interface(\n",
    "   \n",
    "    inputs =\n",
    "    [\n",
    "        { STEP_NAME: \"model_train\", ENTITY_NAME: \"california_bento\" }\n",
    "    ],\n",
    "    outputs = \n",
    "    [\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "substep.print_interface_info()\n",
    "\n",
    "substep.exit_in_visualize_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e950c3-3151-4daf-9b98-83d3aebe216d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session is run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/15 08:55:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/01/15 08:55:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='/proxy/4041/jobs/' target='blank'>Open Spark UI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4 run spark\n",
    "from sinara.spark import SinaraSpark\n",
    "\n",
    "spark = SinaraSpark.run_session(0)\n",
    "SinaraSpark.ui_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70b2d9b3-051c-424c-beec-9da8f177b4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# read inputs \n",
    "bento_step_inputs = substep.inputs(step_name=\"model_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04f8c516-079f-4473-8564-1cf66344872c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-15 08:59:50,650] WARNING - Python 3.10.12 found in current environment is not officially supported by BentoML. The docker base image used is'bentoml/model-server:0.13.2' which will use conda to install Python 3.10.12 in the build process. Supported Python versions are: f3.6, 3.7, 3.8\n",
      "[2025-01-15 08:59:50,773] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.13.2, but loading from BentoML version 0.13.2+6.g2dc5913c\n",
      "[2025-01-15 08:59:50,776] WARNING - Module `model_service` already loaded, using existing imported module.\n",
      "[2025-01-15 08:59:50,793] WARNING - No dev server is running.\n",
      "[2025-01-15 08:59:51,791] INFO - BentoService bundle 'ModelService:user.pipeline.zone.california_bento.run-25-01-15-070811' created at: /tmp/tmpf016k5wp\n",
      "[2025-01-15 08:59:51,798] INFO - ======= starting dev server on port: 5000 =======\n",
      "[2025-01-15 08:59:52,568] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2025-01-15 08:59:52,595] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.13.2, but loading from BentoML version 0.13.2+6.g2dc5913c\n",
      "[2025-01-15 08:59:52,626] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2025-01-15 08:59:52,656] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.13.2, but loading from BentoML version 0.13.2+6.g2dc5913c\n",
      "[2025-01-15 08:59:52,660] INFO - Micro batch enabled for API `predict` max-latency: 20000 max-batch-size 4000\n",
      "[2025-01-15 08:59:52,660] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n",
      "[2025-01-15 08:59:52,678] INFO - Starting BentoML API proxy in development mode..\n",
      "The mean_absolute_error (MAE) on test set: 0.9240\n",
      "The mean_absolute_percentage_errorr (MAPE) on test set: 0.6169\n",
      "[2025-01-15 08:59:53,078] INFO - Dev server has stopped.\n"
     ]
    }
   ],
   "source": [
    "#6 make something to create artifacts\n",
    "# Test model API\n",
    "from sinara.bentoml import start_dev_bentoservice, stop_dev_bentoservice, load_bentoservice\n",
    "from sklearn.metrics import mean_absolute_percentage_error,mean_absolute_error\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load BentoService\n",
    "bento_serv = load_bentoservice(bento_step_inputs.california_bento)\n",
    "\n",
    "# Stop a dev model server if running\n",
    "stop_dev_bentoservice(bento_serv)\n",
    "\n",
    "# Start a dev model server to test out the API endpoint locally\n",
    "start_dev_bentoservice(bento_serv)\n",
    "\n",
    "serv_v = json.loads(requests.post(\"http://127.0.0.1:5000/service_version\", json={}).text)\n",
    "## убрал вывод неудобно\n",
    "#print(serv_v)\n",
    "\n",
    "test_data = json.loads(requests.post(\"http://127.0.0.1:5000/test_data\", json={}).text)\n",
    "\n",
    "preds = json.loads(requests.post(\"http://127.0.0.1:5000/predict\", \n",
    "                                   json=test_data['X']).text)\n",
    "\n",
    "mae = mean_absolute_error(pd.DataFrame(test_data['Y']).values, preds)\n",
    "mape = mean_absolute_percentage_error(pd.DataFrame(test_data['Y']).values, preds)\n",
    "\n",
    "print(\"The mean_absolute_error (MAE) on test set: {:.4f}\".format(mae))\n",
    "print(\"The mean_absolute_percentage_errorr (MAPE) on test set: {:.4f}\".format(mape))\n",
    "\n",
    "# Stop the dev model server\n",
    "stop_dev_bentoservice(bento_serv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59722cc0-3f1b-4ff7-9c0f-23707a8daee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-15 09:00:07,190] WARNING - Python 3.10.12 found in current environment is not officially supported by BentoML. The docker base image used is'bentoml/model-server:0.13.2' which will use conda to install Python 3.10.12 in the build process. Supported Python versions are: f3.6, 3.7, 3.8\n"
     ]
    }
   ],
   "source": [
    "# check eval result\n",
    "mae_threshold = substep_params[\"mae_threshold\"]\n",
    "mape_threshold = substep_params[\"mape_threshold\"]\n",
    "if mae > mae_threshold:\n",
    "    raise Exception(f'MAE is {mae}, more than acceptable value of {mae_threshold}')\n",
    "if mape > mape_threshold:\n",
    "    raise Exception(f'MAPE is {mape}, more than acceptable value of {mape_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08fd9276-08de-416b-935e-aa59a032b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop spark\n",
    "SinaraSpark.stop_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158d412-3ae9-4a16-b7fe-9639c9653bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
